{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LAB8.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z-1ltMfN9JUe","colab_type":"code","colab":{}},"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import torchvision.datasets as datasets\n","import pandas as pd\n","from torch.utils.data.dataset import Dataset\n","from torchvision import transforms\n","# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper parameters\n","num_epochs = 3\n","num_classes = 10\n","batch_size = 5\n","learning_rate = 0.001"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ps-h3HL6AFI_","colab_type":"text"},"source":["\n","Convolutional neural network (two convolutional layers)"]},{"cell_type":"code","metadata":{"id":"9xByZQVh-zyB","colab_type":"code","colab":{}},"source":["class ConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.fc = nn.Linear(7*7*32, num_classes)\n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model = ConvNet(num_classes).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1IZBhKw_-2F","colab_type":"text"},"source":["Custom datatset loader\n","    based on https://github.com/utkuozbulak/pytorch-custom-dataset-examples\n"]},{"cell_type":"code","metadata":{"id":"yVIsDeRd_pub","colab_type":"code","colab":{}},"source":["class SimpleDataset(Dataset):\n","    def __init__(self, data_path, csv_name, transform = None ):\n","        \"\"\"\n","        Args:\n","            data_path (string): path to the folder where images and csv files are located\n","            csv_name (string): name of the csv lablel file\n","            transform: pytorch transforms for transforms and tensor conversion\n","        \"\"\"\n","        # Set path\n","        self.data_path = data_path\n","        # Transforms\n","        self.transform = transform\n","        # Read the csv file\n","        self.data_info = pd.read_csv(data_path + csv_name, header=None)\n","        # First column contains the image paths\n","        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n","        # Second column is the labels\n","        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n","        # Calculate len\n","        self.data_len = len(self.data_info.index)\n","        \n","\n","    def __getitem__(self, index):\n","        # Get image name from the pandas df\n","        single_image_name = self.image_arr[index]\n","        # Open image\n","        img_as_img = Image.open(self.data_path + single_image_name)\n","        if self.transform is not None:\n","              img_as_img = self.transform(img_as_img)\n","\n","        # Get label(class) of the image based on the cropped pandas column\n","        single_image_label = self.label_arr[index]\n","        #convert to tensor to be consistent with MNIST dataset\n","        single_image_label = torch.LongTensor( [ single_image_label ] )[0]\n","        return (img_as_img, single_image_label)\n","\n"," #   def __len__(self):\n","        return self.data_len\n","\n","#mydata = SimpleDataset( \"./imageset/\", \"label.csv\")\n","#print(len(mydata))\n","#mydataT = SimpleDataset( \"./imageset/\", \"label.csv\", transform=transforms.ToTensor())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hArCyYBQA8jf","colab_type":"text"},"source":["Task 1 number of training set=60000,20000,5000,1000,500,250,100,50"]},{"cell_type":"code","metadata":{"id":"GVHJQV-C4yrY","colab_type":"code","colab":{}},"source":["# MNIST dataset\n","'''train_dataset = torchvision.datasets.MNIST(root='./data/',train=True,transform=transforms.ToTensor(),download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data/',train=False,transform=transforms.ToTensor())\n","'''\n","train_dataset, temp_dataset = torch.utils.data.random_split(torchvision.datasets.MNIST(root='./data/', train = True, transform=transforms.ToTensor(),download=True), \n","                                                            [50,59950])\n","test_dataset, temp_dataset = torch.utils.data.random_split(torchvision.datasets.MNIST(root='./data/', train = False, transform=transforms.ToTensor(),download=True), [10000,0])\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        #print(i)\n","        if (i+1) % 2000 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YK3omZfW9chg","colab_type":"code","outputId":"74595aad-c08f-40d4-b8f8-a89c417cb9b2","executionInfo":{"status":"ok","timestamp":1574358278547,"user_tz":300,"elapsed":7352,"user":{"displayName":"Jingwen Ye","photoUrl":"","userId":"15808149000234564409"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Test the model with testing dataset\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Test Accuracy of the model on the 10000 test images: 61.97 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"d3280244-5805-46e5-fdf7-ce63c6ff31bd","executionInfo":{"status":"ok","timestamp":1574358296563,"user_tz":300,"elapsed":25354,"user":{"displayName":"Jingwen Ye","photoUrl":"","userId":"15808149000234564409"}},"id":"g3qtt7TTCyV3","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Test the model with training dataset\n","train_dataset = torchvision.datasets.MNIST(root='./data/',train=True,transform=transforms.ToTensor(),download=True)\n","test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","print(len(train_dataset))\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["60000\n","Test Accuracy of the model on the 10000 test images: 60.455 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lIP498Zj9e95","colab_type":"code","colab":{}},"source":["# Save the model checkpoint\n","if (len(train_dataset)==60000):\n","  torch.save(model.state_dict(), 'model1_full.ckpt')\n","# Save the model checkpoint\n","if (len(train_dataset)==50):\n","  torch.save(model.state_dict(), 'model1_50.ckpt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qtcbrQymBB6J","colab_type":"text"},"source":["Task 2"]},{"cell_type":"code","metadata":{"id":"4YjpuAe490ji","colab_type":"code","outputId":"4b22a720-90fd-4de2-e5fc-e0ad2c7aa97a","executionInfo":{"status":"ok","timestamp":1574358296565,"user_tz":300,"elapsed":25336,"user":{"displayName":"Jingwen Ye","photoUrl":"","userId":"15808149000234564409"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Load the network from a previously saved check point\n","model.load_state_dict(torch.load('model1_full.ckpt'))"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"IFr3i8De8bSh","colab_type":"code","outputId":"3bf0ac8d-9e46-4dbf-a8d6-b174e6eb3202","executionInfo":{"status":"error","timestamp":1574358296751,"user_tz":300,"elapsed":25513,"user":{"displayName":"Jingwen Ye","photoUrl":"","userId":"15808149000234564409"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["from PIL import Image\n","# Test the model with full MNIST training dataset\n","test_dataset = torchvision.datasets.MNIST(root='./data/',train=True,transform=transforms.ToTensor())\n","print(mydataT)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-f887e00a7718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Test the model with full MNIST training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydataT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n\u001b[1;32m      6\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mydataT' is not defined"]}]}]}